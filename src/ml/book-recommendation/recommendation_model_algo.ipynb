{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommender System in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 900\n",
    "\n",
    "epochs = 10\n",
    "display_step = 10\n",
    "\n",
    "learning_rate = 0.3\n",
    "\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1052, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_reviews = 'SELECT user_id, book_id, rating, date_created FROM public.\"Reviews\"'\n",
    "\n",
    "sql_books = 'SELECT book_id FROM public.\"Books\"'\n",
    "\n",
    "engine = create_engine('postgresql://ece651_ml:TVL3MV0mguz0DOhLbbm2@localhost:5432/ece651')\n",
    "\n",
    "df = pd.pandas.read_sql(sql_reviews, engine)\n",
    "df_books = pd.pandas.read_sql(sql_books, engine)\n",
    "\n",
    "i1 = df_books.set_index('book_id').index\n",
    "i2 = df.set_index('book_id').index\n",
    "books = df_books[~i1.isin(i2)]\n",
    "\n",
    "rows, column = books.shape\n",
    "empty_array = np.zeros((rows, 1))\n",
    "unrated_books = np.hstack((empty_array, books.values, empty_array, empty_array))\n",
    "unrated_books = pd.DataFrame(unrated_books)\n",
    "unrated_books.columns = ['user_id', 'book_id', 'rating', 'date_created']\n",
    "\n",
    "df = df.append(unrated_books, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset and splitting it in a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERS: 149 BOOKS: 866\n"
     ]
    }
   ],
   "source": [
    "y = df.date_created\n",
    "df = df.drop('date_created', axis=1)\n",
    "\n",
    "df.columns = ['user', 'book', 'rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
    "\n",
    "train_data = X_train\n",
    "test_data = X_test\n",
    "\n",
    "num_books = df.book.nunique()\n",
    "num_users = df.user.nunique()\n",
    "\n",
    "print(\"USERS: {} BOOKS: {}\".format(num_users, num_books))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training set with three columns: user, book and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize in [0, 1]\n",
    "\n",
    "u = df['user'].values.astype(float)\n",
    "\n",
    "user_min = u.min()\n",
    "user_range = u.max() - u.min()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(u.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['user'] = df_normalized\n",
    "\n",
    "b = df['book'].values.astype(float)\n",
    "\n",
    "book_min = b.min()\n",
    "book_range = b.max() - b.min()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(b.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['book'] = df_normalized\n",
    "\n",
    "r = df['rating'].values.astype(float)\n",
    "\n",
    "rating_min = r.min()\n",
    "rating_range = r.max() - r.min()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(r.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['rating'] = df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert DataFrame in user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = df.pivot(index='user', columns='book', values='rating')\n",
    "matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users and items ordered as they are in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (149, 866)\n"
     ]
    }
   ],
   "source": [
    "users = matrix.index.tolist()\n",
    "books = matrix.columns.tolist()\n",
    "\n",
    "matrix = matrix.values\n",
    "\n",
    "print(\"Matrix shape: {}\".format(matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = num_books   # num of items\n",
    "num_hidden_1 = 10       # 1st layer num features\n",
    "num_hidden_2 = 5        # 2nd layer num features (the latent dim)\n",
    "\n",
    "X = tf.placeholder(tf.float64, [None, num_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    # Encoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decoder_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets are the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer, minimize the squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "predictions = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_x = tf.placeholder(tf.int32, )\n",
    "eval_y = tf.placeholder(tf.int32, )\n",
    "pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.33864107728004456\n",
      "Epoch: 2 Loss: 0.3380974054336548\n",
      "Epoch: 3 Loss: 0.33739207983016967\n",
      "Epoch: 4 Loss: 0.3364780366420746\n",
      "Epoch: 5 Loss: 0.33529374599456785\n",
      "Epoch: 6 Loss: 0.33375962972640993\n",
      "Epoch: 7 Loss: 0.33177323937416076\n",
      "Epoch: 8 Loss: 0.3292016565799713\n",
      "Epoch: 9 Loss: 0.3258721768856049\n",
      "Epoch: 10 Loss: 0.32158333659172056\n",
      "Predictions...\n",
      "        user      book    rating\n",
      "0        0.0  0.000000  0.810368\n",
      "1        0.0  0.000407  0.164006\n",
      "2        0.0  0.000815  0.160680\n",
      "3        0.0  0.005295  0.785815\n",
      "4        0.0  0.007739  0.865465\n",
      "5        0.0  0.008554  0.851291\n",
      "6        0.0  0.008961  0.106957\n",
      "7        0.0  0.015886  0.578767\n",
      "8        0.0  0.016293  0.621676\n",
      "9        0.0  0.016701  0.054215\n",
      "10       0.0  0.017515  0.455526\n",
      "11       0.0  0.018330  0.049377\n",
      "12       0.0  0.018737  0.126097\n",
      "13       0.0  0.019145  0.804265\n",
      "14       0.0  0.019552  0.798201\n",
      "15       0.0  0.019959  0.939688\n",
      "16       0.0  0.020367  0.145524\n",
      "17       0.0  0.020774  0.149915\n",
      "18       0.0  0.021181  0.873405\n",
      "19       0.0  0.021589  0.318041\n",
      "20       0.0  0.021996  0.840979\n",
      "21       0.0  0.022403  0.878527\n",
      "22       0.0  0.023218  0.261254\n",
      "23       0.0  0.023625  0.151288\n",
      "24       0.0  0.024033  0.847138\n",
      "25       0.0  0.024440  0.625755\n",
      "26       0.0  0.024847  0.232042\n",
      "27       0.0  0.025255  0.599224\n",
      "28       0.0  0.025662  0.190780\n",
      "29       0.0  0.026069  0.949713\n",
      "...      ...       ...       ...\n",
      "129004   1.0  0.911202  0.192741\n",
      "129005   1.0  0.917312  0.395371\n",
      "129006   1.0  0.917719  0.226241\n",
      "129007   1.0  0.918126  0.239166\n",
      "129008   1.0  0.918534  0.331754\n",
      "129009   1.0  0.918941  0.416633\n",
      "129010   1.0  0.942566  0.672032\n",
      "129011   1.0  0.942974  0.408523\n",
      "129012   1.0  0.943381  0.361173\n",
      "129013   1.0  0.944196  0.960718\n",
      "129014   1.0  0.945010  0.931774\n",
      "129015   1.0  0.945825  0.248350\n",
      "129016   1.0  0.946232  0.149722\n",
      "129017   1.0  0.946640  0.264215\n",
      "129018   1.0  0.952342  0.670186\n",
      "129019   1.0  0.952749  0.551941\n",
      "129020   1.0  0.962525  0.301422\n",
      "129021   1.0  0.963340  0.136909\n",
      "129022   1.0  0.994297  0.090362\n",
      "129023   1.0  0.994705  0.795024\n",
      "129024   1.0  0.995112  0.102286\n",
      "129025   1.0  0.996741  0.348853\n",
      "129026   1.0  0.997149  0.513830\n",
      "129027   1.0  0.997556  0.650425\n",
      "129028   1.0  0.997963  0.843585\n",
      "129029   1.0  0.998371  0.006222\n",
      "129030   1.0  0.998778  0.160142\n",
      "129031   1.0  0.999185  0.545013\n",
      "129032   1.0  0.999593  0.235811\n",
      "129033   1.0  1.000000  0.326790\n",
      "\n",
      "[129034 rows x 3 columns]\n",
      "(129034, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(local_init)\n",
    "\n",
    "    num_batches = int(matrix.shape[0] / batch_size)\n",
    "    matrix = np.array_split(matrix, num_batches)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_cost = 0\n",
    "\n",
    "        for batch in matrix:\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "        print(\"Epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "\n",
    "        # if i % display_step == 0 or i == 1:\n",
    "        #     print('Step %i: Minibatch Loss: %f' % (i, l))\n",
    "\n",
    "    print(\"Predictions...\")\n",
    "\n",
    "    matrix = np.concatenate(matrix, axis=0)\n",
    "\n",
    "    preds = session.run(decoder_op, feed_dict={X: matrix})\n",
    "\n",
    "    # print(matrix)\n",
    "    # print(preds)\n",
    "    \n",
    "    predictions = predictions.append(pd.DataFrame(preds))\n",
    "\n",
    "    predictions = predictions.stack().reset_index(name='rating')\n",
    "    predictions.columns = ['user', 'book', 'rating']\n",
    "    predictions['user'] = predictions['user'].map(lambda value: users[value])\n",
    "    predictions['book'] = predictions['book'].map(lambda value: books[value])\n",
    "\n",
    "    print(predictions)\n",
    "    print(predictions.shape)\n",
    "    \n",
    "    keys = ['user', 'book']\n",
    "    i1 = predictions.set_index(keys).index\n",
    "    i2 = df.set_index(keys).index\n",
    "\n",
    "    recs = predictions\n",
    "    recs = recs.sort_values(['user', 'rating'], ascending=[True, False])\n",
    "    recs = recs.groupby('user').head(k)\n",
    "    recs.to_csv('prediction.csv', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>book</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>0.995294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.989386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.989376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>0.987114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.984228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.983096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.981829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>0.980299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.979722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.979115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>0.978632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>0.975692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.974661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.974072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>0.973242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.972184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.970741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.969127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.966545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>0.962622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.959550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.957537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.957330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>0.956603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.955895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2339.0</td>\n",
       "      <td>0.954041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.952950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>0.952677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.949713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>0.949298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128911</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>0.043011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128723</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>0.043009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128334</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.042220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128312</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.041961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128246</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.039323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128616</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.038711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128830</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>0.038327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128474</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>0.038220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128207</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.037935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128274</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.037913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128400</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.037547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128672</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.034578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128754</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>0.033657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128571</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>0.033188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128858</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>0.032247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128593</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>0.030341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128232</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.029037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128851</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>0.028967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128666</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>0.028231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128661</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>0.027906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128895</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>0.027280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128700</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>0.023411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128915</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>0.018202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128408</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.017007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128405</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0.016437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128696</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>0.012182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128541</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>0.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128668</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>0.011216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128759</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>0.010175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129029</th>\n",
       "      <td>2533.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>0.006222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129034 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user    book    rating\n",
       "695        0.0  1214.0  0.995294\n",
       "791        0.0  1821.0  0.989386\n",
       "116        0.0   191.0  0.989376\n",
       "707        0.0  1307.0  0.987114\n",
       "134        0.0   244.0  0.984228\n",
       "203        0.0   361.0  0.983096\n",
       "285        0.0   448.0  0.981829\n",
       "745        0.0  1510.0  0.980299\n",
       "645        0.0  1124.0  0.979722\n",
       "127        0.0   207.0  0.979115\n",
       "465        0.0   787.0  0.978632\n",
       "652        0.0  1139.0  0.975692\n",
       "278        0.0   441.0  0.974661\n",
       "139        0.0   266.0  0.974072\n",
       "478        0.0   802.0  0.973242\n",
       "663        0.0  1156.0  0.972184\n",
       "592        0.0   994.0  0.970741\n",
       "541        0.0   932.0  0.969127\n",
       "469        0.0   791.0  0.966545\n",
       "612        0.0  1036.0  0.962622\n",
       "305        0.0   471.0  0.959550\n",
       "225        0.0   385.0  0.957537\n",
       "107        0.0   178.0  0.957330\n",
       "518        0.0   905.0  0.956603\n",
       "413        0.0   674.0  0.955895\n",
       "845        0.0  2339.0  0.954041\n",
       "130        0.0   229.0  0.952950\n",
       "811        0.0  2096.0  0.952677\n",
       "29         0.0    85.0  0.949713\n",
       "505        0.0   832.0  0.949298\n",
       "...        ...     ...       ...\n",
       "128911  2533.0  1420.0  0.043011\n",
       "128723  2533.0   947.0  0.043009\n",
       "128334  2533.0   320.0  0.042220\n",
       "128312  2533.0   276.0  0.041961\n",
       "128246  2533.0   148.0  0.039323\n",
       "128616  2533.0   768.0  0.038711\n",
       "128830  2533.0  1155.0  0.038327\n",
       "128474  2533.0   472.0  0.038220\n",
       "128207  2533.0   100.0  0.037935\n",
       "128274  2533.0   177.0  0.037913\n",
       "128400  2533.0   392.0  0.037547\n",
       "128672  2533.0   831.0  0.034578\n",
       "128754  2533.0   985.0  0.033657\n",
       "128571  2533.0   662.0  0.033188\n",
       "128858  2533.0  1205.0  0.032247\n",
       "128593  2533.0   688.0  0.030341\n",
       "128232  2533.0   129.0  0.029037\n",
       "128851  2533.0  1194.0  0.028967\n",
       "128666  2533.0   825.0  0.028231\n",
       "128661  2533.0   820.0  0.027906\n",
       "128895  2533.0  1367.0  0.027280\n",
       "128700  2533.0   921.0  0.023411\n",
       "128915  2533.0  1527.0  0.018202\n",
       "128408  2533.0   401.0  0.017007\n",
       "128405  2533.0   398.0  0.016437\n",
       "128696  2533.0   916.0  0.012182\n",
       "128541  2533.0   591.0  0.011905\n",
       "128668  2533.0   827.0  0.011216\n",
       "128759  2533.0   993.0  0.010175\n",
       "129029  2533.0  2472.0  0.006222\n",
       "\n",
       "[129034 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs['user'] = recs['user'] * user_range + user_min\n",
    "recs['book'] = recs['book'] * book_range + book_min\n",
    "\n",
    "recs.sort_values(['user', 'rating'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>book</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64779</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>0.993909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64875</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.989050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64200</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.988874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64791</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>0.984584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64218</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.984230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64369</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.981820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64287</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.981719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64729</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.980512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64829</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>0.978501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64549</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>0.978365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64211</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.976432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64223</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.973441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64736</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>0.970754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64362</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.970265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64562</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>0.968369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64625</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.965800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64747</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.965694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64696</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>0.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64676</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.963903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64389</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.960401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64553</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.959809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64602</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>0.956832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64191</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.954685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64309</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.951907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64895</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>0.951246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64589</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>0.951141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64497</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.950521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64544</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>0.948660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64214</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.946703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64432</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.946172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64746</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>0.051871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64827</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>0.050152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64571</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>0.049584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64162</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.049263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64250</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.047434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64880</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>0.047060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64316</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.045793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64267</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.044235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64753</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>0.041942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64487</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64532</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.040282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64499</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>0.037864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64616</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>0.037814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64148</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.036681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64588</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.036467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64577</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>0.035329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64670</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>0.034063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64774</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>0.032290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64767</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>0.030860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64509</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>0.030501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64324</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.029126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64831</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>0.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64582</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>0.024976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64811</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>0.024969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64612</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>0.020543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64321</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0.019625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64584</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>0.014464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64457</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>0.014297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64675</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>0.007059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64945</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>0.005854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user    book    rating\n",
       "64779  2380.0  1214.0  0.993909\n",
       "64875  2380.0  1821.0  0.989050\n",
       "64200  2380.0   191.0  0.988874\n",
       "64791  2380.0  1307.0  0.984584\n",
       "64218  2380.0   244.0  0.984230\n",
       "64369  2380.0   448.0  0.981820\n",
       "64287  2380.0   361.0  0.981719\n",
       "64729  2380.0  1124.0  0.980512\n",
       "64829  2380.0  1510.0  0.978501\n",
       "64549  2380.0   787.0  0.978365\n",
       "64211  2380.0   207.0  0.976432\n",
       "64223  2380.0   266.0  0.973441\n",
       "64736  2380.0  1139.0  0.970754\n",
       "64362  2380.0   441.0  0.970265\n",
       "64562  2380.0   802.0  0.968369\n",
       "64625  2380.0   932.0  0.965800\n",
       "64747  2380.0  1156.0  0.965694\n",
       "64696  2380.0  1036.0  0.964700\n",
       "64676  2380.0   994.0  0.963903\n",
       "64389  2380.0   471.0  0.960401\n",
       "64553  2380.0   791.0  0.959809\n",
       "64602  2380.0   905.0  0.956832\n",
       "64191  2380.0   178.0  0.954685\n",
       "64309  2380.0   385.0  0.951907\n",
       "64895  2380.0  2096.0  0.951246\n",
       "64589  2380.0   832.0  0.951141\n",
       "64497  2380.0   674.0  0.950521\n",
       "64544  2380.0   782.0  0.948660\n",
       "64214  2380.0   229.0  0.946703\n",
       "64432  2380.0   522.0  0.946172\n",
       "...       ...     ...       ...\n",
       "64746  2380.0  1155.0  0.051871\n",
       "64827  2380.0  1420.0  0.050152\n",
       "64571  2380.0   813.0  0.049584\n",
       "64162  2380.0   148.0  0.049263\n",
       "64250  2380.0   320.0  0.047434\n",
       "64880  2380.0  1851.0  0.047060\n",
       "64316  2380.0   392.0  0.045793\n",
       "64267  2380.0   339.0  0.044235\n",
       "64753  2380.0  1180.0  0.041942\n",
       "64487  2380.0   662.0  0.041359\n",
       "64532  2380.0   768.0  0.040282\n",
       "64499  2380.0   676.0  0.037864\n",
       "64616  2380.0   921.0  0.037814\n",
       "64148  2380.0   129.0  0.036681\n",
       "64588  2380.0   831.0  0.036467\n",
       "64577  2380.0   820.0  0.035329\n",
       "64670  2380.0   985.0  0.034063\n",
       "64774  2380.0  1205.0  0.032290\n",
       "64767  2380.0  1194.0  0.030860\n",
       "64509  2380.0   688.0  0.030501\n",
       "64324  2380.0   401.0  0.029126\n",
       "64831  2380.0  1527.0  0.026065\n",
       "64582  2380.0   825.0  0.024976\n",
       "64811  2380.0  1367.0  0.024969\n",
       "64612  2380.0   916.0  0.020543\n",
       "64321  2380.0   398.0  0.019625\n",
       "64584  2380.0   827.0  0.014464\n",
       "64457  2380.0   591.0  0.014297\n",
       "64675  2380.0   993.0  0.007059\n",
       "64945  2380.0  2472.0  0.005854\n",
       "\n",
       "[866 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs.loc[recs['user'] == 2380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs.loc[recs['user'] == 2380]['book'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_2380_top = recs.loc[recs['user'] == 2380]\n",
    "\n",
    "expected_2380_book_ids = [382,670,662,375,677];\n",
    "for x in expected_2380_book_ids:\n",
    "    if x not in user_2380_top['book'].values.round(): \n",
    "        print(f'Couldn\\'t find {x} for user 2380')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>book</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>0.992860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.986707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>1.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.986207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>0.984214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.984171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.982693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>0.977465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>1.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.976812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>0.976706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.974471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.974447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.972632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.972026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>0.970628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0.968399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.968016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>0.967717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>1.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.967295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.967011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.966479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>0.957919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.957463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.956472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.953430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>1.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>0.950902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>1.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.949330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.949036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>1.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>0.948215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>0.946384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>0.946384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>1.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>1.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>0.052492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>0.050223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>0.047879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.047762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.047582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>0.045620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>0.042700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.042244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>0.041620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>1.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>0.041326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>0.039841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>1.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>0.039067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>0.038872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>1.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>0.038861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>0.037915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.037684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.032083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.031881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>0.031774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>0.029832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>0.029160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>1.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>0.026763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.023709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0.022860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>0.017635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>0.015902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>1.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>0.015812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>0.013075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>0.006584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user    book    rating\n",
       "1561   1.0  1214.0  0.992860\n",
       "1000   1.0   244.0  0.986707\n",
       "982    1.0   191.0  0.986207\n",
       "1573   1.0  1307.0  0.984214\n",
       "1657   1.0  1821.0  0.984171\n",
       "1069   1.0   361.0  0.982693\n",
       "1344   1.0   802.0  0.977465\n",
       "993    1.0   207.0  0.976812\n",
       "1611   1.0  1510.0  0.976706\n",
       "1511   1.0  1124.0  0.974471\n",
       "1144   1.0   441.0  0.974447\n",
       "1529   1.0  1156.0  0.972632\n",
       "1458   1.0   994.0  0.972026\n",
       "1518   1.0  1139.0  0.970628\n",
       "1540   1.0  1185.0  0.968399\n",
       "1407   1.0   932.0  0.968016\n",
       "1331   1.0   787.0  0.967717\n",
       "1151   1.0   448.0  0.967295\n",
       "1005   1.0   266.0  0.967011\n",
       "1335   1.0   791.0  0.966479\n",
       "1478   1.0  1036.0  0.957919\n",
       "895    1.0    85.0  0.957463\n",
       "1279   1.0   674.0  0.956472\n",
       "1030   1.0   318.0  0.953430\n",
       "1326   1.0   782.0  0.950902\n",
       "1171   1.0   471.0  0.949330\n",
       "881    1.0    70.0  0.949036\n",
       "1384   1.0   905.0  0.948215\n",
       "1677   1.0  2096.0  0.946384\n",
       "1637   1.0  1688.0  0.946384\n",
       "...    ...     ...       ...\n",
       "1010   1.0   276.0  0.054600\n",
       "1119   1.0   415.0  0.052492\n",
       "1535   1.0  1180.0  0.050223\n",
       "1593   1.0  1367.0  0.047879\n",
       "972    1.0   177.0  0.047762\n",
       "1098   1.0   392.0  0.047582\n",
       "1269   1.0   662.0  0.045620\n",
       "1609   1.0  1420.0  0.042700\n",
       "1314   1.0   768.0  0.042244\n",
       "1452   1.0   985.0  0.041620\n",
       "1421   1.0   947.0  0.041326\n",
       "1291   1.0   688.0  0.039841\n",
       "1359   1.0   820.0  0.039067\n",
       "1528   1.0  1155.0  0.038872\n",
       "1364   1.0   825.0  0.038861\n",
       "1441   1.0   969.0  0.037915\n",
       "1049   1.0   339.0  0.037684\n",
       "1370   1.0   831.0  0.032083\n",
       "930    1.0   129.0  0.031881\n",
       "1398   1.0   921.0  0.031774\n",
       "1549   1.0  1194.0  0.029832\n",
       "1556   1.0  1205.0  0.029160\n",
       "1394   1.0   916.0  0.026763\n",
       "1106   1.0   401.0  0.023709\n",
       "1103   1.0   398.0  0.022860\n",
       "1613   1.0  1527.0  0.017635\n",
       "1239   1.0   591.0  0.015902\n",
       "1366   1.0   827.0  0.015812\n",
       "1457   1.0   993.0  0.013075\n",
       "1727   1.0  2472.0  0.006584\n",
       "\n",
       "[866 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs.loc[recs['user'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs.loc[recs['user'] == 1]['book'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find 1387 for user 1\n",
      "Couldn't find 1374 for user 1\n",
      "Couldn't find 1420 for user 1\n",
      "Couldn't find 1526 for user 1\n",
      "Couldn't find 1308 for user 1\n",
      "Couldn't find 1384 for user 1\n",
      "Couldn't find 1210 for user 1\n",
      "Couldn't find 1385 for user 1\n"
     ]
    }
   ],
   "source": [
    "user_1_top = recs.loc[recs['user'] == 1]\n",
    "\n",
    "expected_1_book_ids = [1387,1374,1420,1526,1308,1384,1210,1385];\n",
    "for x in expected_1_book_ids:\n",
    "    if x not in user_1_top['book'].values.round(): \n",
    "        print(f'Couldn\\'t find {x} for user 1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
