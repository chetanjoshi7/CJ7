{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommender System in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 900\n",
    "\n",
    "epochs = 10\n",
    "display_step = 10\n",
    "\n",
    "learning_rate = 0.3\n",
    "\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1052, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_reviews = 'SELECT user_id, book_id, rating, date_created FROM public.\"Reviews\"'\n",
    "\n",
    "sql_books = 'SELECT book_id FROM public.\"Books\"'\n",
    "\n",
    "engine = create_engine('postgresql://ece651_ml:TVL3MV0mguz0DOhLbbm2@localhost:5432/ece651')\n",
    "\n",
    "df = pd.pandas.read_sql(sql_reviews, engine)\n",
    "df_books = pd.pandas.read_sql(sql_books, engine)\n",
    "\n",
    "i1 = df_books.set_index('book_id').index\n",
    "i2 = df.set_index('book_id').index\n",
    "books = df_books[~i1.isin(i2)]\n",
    "\n",
    "rows, column = books.shape\n",
    "empty_array = np.zeros((rows, 1))\n",
    "unrated_books = np.hstack((empty_array, books.values, empty_array, empty_array))\n",
    "unrated_books = pd.DataFrame(unrated_books)\n",
    "unrated_books.columns = ['user_id', 'book_id', 'rating', 'date_created']\n",
    "\n",
    "df = df.append(unrated_books, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset and splitting it in a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERS: 148 BOOKS: 866\n"
     ]
    }
   ],
   "source": [
    "y = df.date_created\n",
    "df = df.drop('date_created', axis=1)\n",
    "\n",
    "df.columns = ['user', 'book', 'rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
    "\n",
    "train_data = X_train\n",
    "test_data = X_test\n",
    "\n",
    "num_books = df.book.nunique()\n",
    "num_users = df.user.nunique()\n",
    "\n",
    "print(\"USERS: {} BOOKS: {}\".format(num_users, num_books))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training set with three columns: user, book and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize in [0, 1]\n",
    "\n",
    "u = df['user'].values.astype(float)\n",
    "\n",
    "user_min = u.min()\n",
    "user_range = u.max() - u.min()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(u.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['user'] = df_normalized\n",
    "\n",
    "b = df['book'].values.astype(float)\n",
    "\n",
    "book_min = b.min()\n",
    "book_range = b.max() - b.min()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(b.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['book'] = df_normalized\n",
    "\n",
    "r = df['rating'].values.astype(float)\n",
    "\n",
    "rating_min = r.min()\n",
    "rating_range = r.max() - r.min()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(r.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['rating'] = df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert DataFrame in user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = df.pivot(index='user', columns='book', values='rating')\n",
    "matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users and items ordered as they are in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (148, 866)\n"
     ]
    }
   ],
   "source": [
    "users = matrix.index.tolist()\n",
    "books = matrix.columns.tolist()\n",
    "\n",
    "matrix = matrix.values\n",
    "\n",
    "print(\"Matrix shape: {}\".format(matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = num_books   # num of items\n",
    "num_hidden_1 = 10       # 1st layer num features\n",
    "num_hidden_2 = 5        # 2nd layer num features (the latent dim)\n",
    "\n",
    "X = tf.placeholder(tf.float64, [None, num_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    # Encoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decoder_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets are the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer, minimize the squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "predictions = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_x = tf.placeholder(tf.int32, )\n",
    "eval_y = tf.placeholder(tf.int32, )\n",
    "pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.3260860204696655\n",
      "Epoch: 2 Loss: 0.32541964650154115\n",
      "Epoch: 3 Loss: 0.3245575726032257\n",
      "Epoch: 4 Loss: 0.32344475388526917\n",
      "Epoch: 5 Loss: 0.3220130860805511\n",
      "Epoch: 6 Loss: 0.3201813757419586\n",
      "Epoch: 7 Loss: 0.3178592026233673\n",
      "Epoch: 8 Loss: 0.31496134400367737\n",
      "Epoch: 9 Loss: 0.3114425539970398\n",
      "Epoch: 10 Loss: 0.307342404127121\n",
      "Predictions...\n",
      "        user      book    rating\n",
      "0        0.0  0.000000  0.091016\n",
      "1        0.0  0.000407  0.087472\n",
      "2        0.0  0.000815  0.329781\n",
      "3        0.0  0.005295  0.512410\n",
      "4        0.0  0.007739  0.910046\n",
      "5        0.0  0.008554  0.348876\n",
      "6        0.0  0.008961  0.238703\n",
      "7        0.0  0.015886  0.811999\n",
      "8        0.0  0.016293  0.091394\n",
      "9        0.0  0.016701  0.569199\n",
      "10       0.0  0.017515  0.093598\n",
      "11       0.0  0.018330  0.229532\n",
      "12       0.0  0.018737  0.517796\n",
      "13       0.0  0.019145  0.137648\n",
      "14       0.0  0.019552  0.159122\n",
      "15       0.0  0.019959  0.327069\n",
      "16       0.0  0.020367  0.195748\n",
      "17       0.0  0.020774  0.688759\n",
      "18       0.0  0.021181  0.371422\n",
      "19       0.0  0.021589  0.873883\n",
      "20       0.0  0.021996  0.252308\n",
      "21       0.0  0.022403  0.266643\n",
      "22       0.0  0.023218  0.168682\n",
      "23       0.0  0.023625  0.222937\n",
      "24       0.0  0.024033  0.421904\n",
      "25       0.0  0.024440  0.468210\n",
      "26       0.0  0.024847  0.566284\n",
      "27       0.0  0.025255  0.587390\n",
      "28       0.0  0.025662  0.019629\n",
      "29       0.0  0.026069  0.187064\n",
      "...      ...       ...       ...\n",
      "128138   1.0  0.911202  0.730855\n",
      "128139   1.0  0.917312  0.852547\n",
      "128140   1.0  0.917719  0.466761\n",
      "128141   1.0  0.918126  0.931315\n",
      "128142   1.0  0.918534  0.902843\n",
      "128143   1.0  0.918941  0.450208\n",
      "128144   1.0  0.942566  0.931060\n",
      "128145   1.0  0.942974  0.392488\n",
      "128146   1.0  0.943381  0.499116\n",
      "128147   1.0  0.944196  0.900234\n",
      "128148   1.0  0.945010  0.311408\n",
      "128149   1.0  0.945825  0.599960\n",
      "128150   1.0  0.946232  0.890723\n",
      "128151   1.0  0.946640  0.246953\n",
      "128152   1.0  0.952342  0.673798\n",
      "128153   1.0  0.952749  0.431121\n",
      "128154   1.0  0.962525  0.452581\n",
      "128155   1.0  0.963340  0.356075\n",
      "128156   1.0  0.994297  0.416193\n",
      "128157   1.0  0.994705  0.236679\n",
      "128158   1.0  0.995112  0.832906\n",
      "128159   1.0  0.996741  0.388488\n",
      "128160   1.0  0.997149  0.418496\n",
      "128161   1.0  0.997556  0.628006\n",
      "128162   1.0  0.997963  0.895639\n",
      "128163   1.0  0.998371  0.951952\n",
      "128164   1.0  0.998778  0.544936\n",
      "128165   1.0  0.999185  0.626576\n",
      "128166   1.0  0.999593  0.714796\n",
      "128167   1.0  1.000000  0.436460\n",
      "\n",
      "[128168 rows x 3 columns]\n",
      "(128168, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(local_init)\n",
    "\n",
    "    num_batches = int(matrix.shape[0] / batch_size)\n",
    "    matrix = np.array_split(matrix, num_batches)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_cost = 0\n",
    "\n",
    "        for batch in matrix:\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "        print(\"Epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "\n",
    "        # if i % display_step == 0 or i == 1:\n",
    "        #     print('Step %i: Minibatch Loss: %f' % (i, l))\n",
    "\n",
    "    print(\"Predictions...\")\n",
    "\n",
    "    matrix = np.concatenate(matrix, axis=0)\n",
    "\n",
    "    preds = session.run(decoder_op, feed_dict={X: matrix})\n",
    "\n",
    "    # print(matrix)\n",
    "    # print(preds)\n",
    "    \n",
    "    predictions = predictions.append(pd.DataFrame(preds))\n",
    "\n",
    "    predictions = predictions.stack().reset_index(name='rating')\n",
    "    predictions.columns = ['user', 'book', 'rating']\n",
    "    predictions['user'] = predictions['user'].map(lambda value: users[value])\n",
    "    predictions['book'] = predictions['book'].map(lambda value: books[value])\n",
    "\n",
    "    print(predictions)\n",
    "    print(predictions.shape)\n",
    "    \n",
    "    keys = ['user', 'book']\n",
    "    i1 = predictions.set_index(keys).index\n",
    "    i2 = df.set_index(keys).index\n",
    "\n",
    "    recs = predictions\n",
    "    recs = recs.sort_values(['user', 'rating'], ascending=[True, False])\n",
    "    recs.to_csv('prediction.csv', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>book</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.990523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>0.990183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.984451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.984270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>0.974646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.974327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.974144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>0.973073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>0.968619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.966386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.966225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>0.965767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.963492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>0.962371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0.956240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>0.955555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.950986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>0.949901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>0.946811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.941122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.938702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.938098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>0.936468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.934439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>0.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>0.933270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.932219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.931730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>0.931687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.930599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>0.929030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127964</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>0.042343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127547</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.041538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127767</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>0.041252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127531</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>0.040508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127948</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>0.040365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127356</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.039042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128032</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>0.038153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127788</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0.037339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127751</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0.036728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128004</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>0.035802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127359</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.033650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127777</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.033148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127383</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.032929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127400</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.030377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127894</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.028302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127671</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.027457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127808</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>0.026538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127504</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.023805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127521</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.021305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127330</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.021076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127909</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128008</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>0.020046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127510</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127757</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>0.015363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127945</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.013529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127943</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>0.012411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128043</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>0.010363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127817</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.009197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127441</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.008192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127959</th>\n",
       "      <td>2522.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>0.005404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user    book    rating\n",
       "320        0.0   487.0  0.990523\n",
       "489        0.0   816.0  0.990183\n",
       "117        0.0   193.0  0.984451\n",
       "31         0.0    88.0  0.984270\n",
       "559        0.0   951.0  0.974646\n",
       "594        0.0  1003.0  0.974327\n",
       "663        0.0  1156.0  0.974144\n",
       "477        0.0   801.0  0.973073\n",
       "561        0.0   953.0  0.968619\n",
       "279        0.0   442.0  0.966386\n",
       "149        0.0   292.0  0.966225\n",
       "496        0.0   823.0  0.965767\n",
       "64         0.0   129.0  0.963492\n",
       "548        0.0   939.0  0.962371\n",
       "335        0.0   506.0  0.956240\n",
       "570        0.0   964.0  0.955555\n",
       "385        0.0   620.0  0.950986\n",
       "246        0.0   407.0  0.949901\n",
       "743        0.0  1420.0  0.946811\n",
       "186        0.0   343.0  0.941122\n",
       "101        0.0   171.0  0.938702\n",
       "127        0.0   207.0  0.938098\n",
       "861        0.0  2472.0  0.936468\n",
       "70         0.0   140.0  0.934439\n",
       "589        0.0   989.0  0.933270\n",
       "137        0.0   257.0  0.932219\n",
       "59         0.0   122.0  0.931730\n",
       "310        0.0   476.0  0.931687\n",
       "372        0.0   590.0  0.930599\n",
       "622        0.0  1064.0  0.929030\n",
       "...        ...     ...       ...\n",
       "127964  2522.0  1155.0  0.042343\n",
       "127547  2522.0   406.0  0.041538\n",
       "127767  2522.0   787.0  0.041252\n",
       "127531  2522.0   389.0  0.040508\n",
       "127948  2522.0  1126.0  0.040365\n",
       "127356  2522.0   116.0  0.039042\n",
       "128032  2522.0  1370.0  0.038153\n",
       "127788  2522.0   810.0  0.037339\n",
       "127751  2522.0   770.0  0.036728\n",
       "128004  2522.0  1302.0  0.035802\n",
       "127359  2522.0   119.0  0.033650\n",
       "127777  2522.0   799.0  0.033148\n",
       "127383  2522.0   151.0  0.032929\n",
       "127400  2522.0   168.0  0.030377\n",
       "127894  2522.0   994.0  0.028302\n",
       "127671  2522.0   580.0  0.027457\n",
       "127808  2522.0   833.0  0.026538\n",
       "127504  2522.0   360.0  0.023805\n",
       "127521  2522.0   378.0  0.021305\n",
       "127330  2522.0    84.0  0.021076\n",
       "127909  2522.0  1026.0  0.020700\n",
       "128008  2522.0  1306.0  0.020046\n",
       "127510  2522.0   366.0  0.016461\n",
       "127757  2522.0   777.0  0.015363\n",
       "127945  2522.0  1102.0  0.013529\n",
       "127943  2522.0  1096.0  0.012411\n",
       "128043  2522.0  1417.0  0.010363\n",
       "127817  2522.0   899.0  0.009197\n",
       "127441  2522.0   266.0  0.008192\n",
       "127959  2522.0  1145.0  0.005404\n",
       "\n",
       "[128168 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs['user'] = recs['user'] * user_range + user_min\n",
    "recs['book'] = recs['book'] * book_range + book_min\n",
    "\n",
    "recs.sort_values(['user', 'rating'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>book</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64573</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>0.989200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64404</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.989169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64115</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64201</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.982176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64561</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>0.979874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64643</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64678</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.975958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64747</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.974727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64645</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>0.974411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64363</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.971110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64632</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>0.967051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64580</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>0.966029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64233</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.966011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64654</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>0.961630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64148</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.960221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64330</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>0.959507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64419</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0.951928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64185</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.949441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64469</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.948741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64827</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>0.947987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64615</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>0.942331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64187</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.941595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64456</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.941239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64211</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.941107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64879</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>0.938598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64673</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>0.936976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64945</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>0.936682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64154</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.935883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64441</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>0.933222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64270</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.932248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64124</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.045636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64329</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.045522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64786</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>0.045508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64814</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>0.044243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64138</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.043284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64141</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.039608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64570</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0.039265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64730</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>0.039183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64165</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.036699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64549</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>0.036051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64559</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.035904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64695</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.033619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64182</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.032847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64676</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.029581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64313</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>0.029433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64691</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>0.028053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64590</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>0.027353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64453</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.027282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64286</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.023075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64303</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.022961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64539</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>0.022265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64790</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>0.021412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64112</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.020401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64292</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>0.019211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64727</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.016175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64725</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>0.013604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64825</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>0.013359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64599</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.011732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64223</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.009496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64741</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>0.004865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user    book    rating\n",
       "64573  2380.0   816.0  0.989200\n",
       "64404  2380.0   487.0  0.989169\n",
       "64115  2380.0    88.0  0.983133\n",
       "64201  2380.0   193.0  0.982176\n",
       "64561  2380.0   801.0  0.979874\n",
       "64643  2380.0   951.0  0.977487\n",
       "64678  2380.0  1003.0  0.975958\n",
       "64747  2380.0  1156.0  0.974727\n",
       "64645  2380.0   953.0  0.974411\n",
       "64363  2380.0   442.0  0.971110\n",
       "64632  2380.0   939.0  0.967051\n",
       "64580  2380.0   823.0  0.966029\n",
       "64233  2380.0   292.0  0.966011\n",
       "64654  2380.0   964.0  0.961630\n",
       "64148  2380.0   129.0  0.960221\n",
       "64330  2380.0   407.0  0.959507\n",
       "64419  2380.0   506.0  0.951928\n",
       "64185  2380.0   171.0  0.949441\n",
       "64469  2380.0   620.0  0.948741\n",
       "64827  2380.0  1420.0  0.947987\n",
       "64615  2380.0   919.0  0.942331\n",
       "64187  2380.0   173.0  0.941595\n",
       "64456  2380.0   590.0  0.941239\n",
       "64211  2380.0   207.0  0.941107\n",
       "64879  2380.0  1845.0  0.938598\n",
       "64673  2380.0   989.0  0.936976\n",
       "64945  2380.0  2472.0  0.936682\n",
       "64154  2380.0   140.0  0.935883\n",
       "64441  2380.0   544.0  0.933222\n",
       "64270  2380.0   343.0  0.932248\n",
       "...       ...     ...       ...\n",
       "64124  2380.0   101.0  0.045636\n",
       "64329  2380.0   406.0  0.045522\n",
       "64786  2380.0  1302.0  0.045508\n",
       "64814  2380.0  1370.0  0.044243\n",
       "64138  2380.0   116.0  0.043284\n",
       "64141  2380.0   119.0  0.039608\n",
       "64570  2380.0   810.0  0.039265\n",
       "64730  2380.0  1126.0  0.039183\n",
       "64165  2380.0   151.0  0.036699\n",
       "64549  2380.0   787.0  0.036051\n",
       "64559  2380.0   799.0  0.035904\n",
       "64695  2380.0  1035.0  0.033619\n",
       "64182  2380.0   168.0  0.032847\n",
       "64676  2380.0   994.0  0.029581\n",
       "64313  2380.0   389.0  0.029433\n",
       "64691  2380.0  1026.0  0.028053\n",
       "64590  2380.0   833.0  0.027353\n",
       "64453  2380.0   580.0  0.027282\n",
       "64286  2380.0   360.0  0.023075\n",
       "64303  2380.0   378.0  0.022961\n",
       "64539  2380.0   777.0  0.022265\n",
       "64790  2380.0  1306.0  0.021412\n",
       "64112  2380.0    84.0  0.020401\n",
       "64292  2380.0   366.0  0.019211\n",
       "64727  2380.0  1102.0  0.016175\n",
       "64725  2380.0  1096.0  0.013604\n",
       "64825  2380.0  1417.0  0.013359\n",
       "64599  2380.0   899.0  0.011732\n",
       "64223  2380.0   266.0  0.009496\n",
       "64741  2380.0  1145.0  0.004865\n",
       "\n",
       "[866 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs.loc[recs['user'] == 2380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs.loc[recs['user'] == 2380]['book'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_2380_top = recs.loc[recs['user'] == 2380]\n",
    "\n",
    "expected_2380_book_ids = [382.0,670.0,662.0,375.0,677.0];\n",
    "for x in expected_2380_book_ids:\n",
    "    if x not in user_2380_top['book'].values.round(): \n",
    "        print(f'Couldn\\'t find {x} for user 2380')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>book</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>0.990124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>1.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.988206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>1.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>0.984925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.982526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>1.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>0.982147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.980974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>1.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>0.980554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.979420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.975811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>1.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>0.974586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.973833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>0.971049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>0.968999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>1.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.968153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>0.967460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>1.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.961352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.960077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>0.957824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>0.957157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.957104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.952826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.951194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>0.950708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>1.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.948581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>0.945958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0.945803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.944336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1571.0</td>\n",
       "      <td>0.943303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>0.941568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>1.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0.941258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>0.042211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.038611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>0.037882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>0.037111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.036001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.035144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>1.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.034552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0.034030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>0.033868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>0.033556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.031659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>0.031415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>1.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.029825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>0.029064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>1.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.027676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.027451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>0.027336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>1.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>0.022316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.021832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.019926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>0.019155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>1.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>0.018464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.017873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>1.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.017370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>0.013385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>1.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>0.012738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>1.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.010926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.008936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>0.008708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>0.004123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user    book    rating\n",
       "1355   1.0   816.0  0.990124\n",
       "1186   1.0   487.0  0.988206\n",
       "1343   1.0   801.0  0.984925\n",
       "897    1.0    88.0  0.982526\n",
       "1425   1.0   951.0  0.982147\n",
       "983    1.0   193.0  0.980974\n",
       "1427   1.0   953.0  0.980554\n",
       "1460   1.0  1003.0  0.979420\n",
       "1529   1.0  1156.0  0.975811\n",
       "1414   1.0   939.0  0.974586\n",
       "1145   1.0   442.0  0.973833\n",
       "1436   1.0   964.0  0.971049\n",
       "1112   1.0   407.0  0.968999\n",
       "1015   1.0   292.0  0.968153\n",
       "1362   1.0   823.0  0.967460\n",
       "967    1.0   171.0  0.961352\n",
       "930    1.0   129.0  0.960077\n",
       "1397   1.0   919.0  0.957824\n",
       "1661   1.0  1845.0  0.957157\n",
       "969    1.0   173.0  0.957104\n",
       "1238   1.0   590.0  0.952826\n",
       "1251   1.0   620.0  0.951194\n",
       "1609   1.0  1420.0  0.950708\n",
       "993    1.0   207.0  0.948581\n",
       "1223   1.0   544.0  0.945958\n",
       "1201   1.0   506.0  0.945803\n",
       "936    1.0   140.0  0.944336\n",
       "1623   1.0  1571.0  0.943303\n",
       "1727   1.0  2472.0  0.941568\n",
       "1202   1.0   509.0  0.941258\n",
       "...    ...     ...       ...\n",
       "1568   1.0  1302.0  0.042211\n",
       "947    1.0   151.0  0.038611\n",
       "1648   1.0  1744.0  0.037882\n",
       "1596   1.0  1370.0  0.037111\n",
       "920    1.0   116.0  0.036001\n",
       "923    1.0   119.0  0.035144\n",
       "1341   1.0   799.0  0.034552\n",
       "1352   1.0   810.0  0.034030\n",
       "1331   1.0   787.0  0.033868\n",
       "1512   1.0  1126.0  0.033556\n",
       "1477   1.0  1035.0  0.031659\n",
       "1638   1.0  1689.0  0.031415\n",
       "1235   1.0   580.0  0.029825\n",
       "1095   1.0   389.0  0.029064\n",
       "964    1.0   168.0  0.027676\n",
       "1458   1.0   994.0  0.027451\n",
       "1473   1.0  1026.0  0.027336\n",
       "1372   1.0   833.0  0.022316\n",
       "1068   1.0   360.0  0.021832\n",
       "894    1.0    84.0  0.019926\n",
       "1572   1.0  1306.0  0.019155\n",
       "1321   1.0   777.0  0.018464\n",
       "1509   1.0  1102.0  0.017873\n",
       "1085   1.0   378.0  0.017370\n",
       "1607   1.0  1417.0  0.013385\n",
       "1074   1.0   366.0  0.012738\n",
       "1381   1.0   899.0  0.010926\n",
       "1005   1.0   266.0  0.008936\n",
       "1507   1.0  1096.0  0.008708\n",
       "1523   1.0  1145.0  0.004123\n",
       "\n",
       "[866 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs.loc[recs['user'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs.loc[recs['user'] == 1]['book'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_1_top = recs.loc[recs['user'] == 1]\n",
    "\n",
    "expected_1_book_ids = [1387.0,1374.0,1420.0,1526.0,1308.0,1384.0,1210.0,1385.0];\n",
    "for x in expected_1_book_ids:\n",
    "    if x not in user_1_top['book'].values.round(): \n",
    "        print(f'Couldn\\'t find {x} for user 1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
