{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommender System in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "epochs = 10\n",
    "display_step = 10\n",
    "\n",
    "learning_rate = 0.3\n",
    "\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset and splitting it in a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERS: 148 BOOKS: 48\n",
      "   user  book  rating\n",
      "0  2292   360       5\n",
      "1  2293   360       5\n",
      "2  2294   360       5\n",
      "3  2297   655       4\n",
      "4  2295   360       5\n"
     ]
    }
   ],
   "source": [
    "sql = 'SELECT user_id, book_id, rating, date_created FROM public.\"Reviews\"'\n",
    "\n",
    "engine = create_engine('postgresql://ece651_ml:TVL3MV0mguz0DOhLbbm2@localhost:5432/ece651')\n",
    "\n",
    "# Reading dataset\n",
    "\n",
    "df = pd.pandas.read_sql(sql, engine)\n",
    "\n",
    "y = df.date_created\n",
    "df = df.drop('date_created', axis=1)\n",
    "\n",
    "df.columns = ['user', 'book', 'rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
    "\n",
    "train_data = X_train\n",
    "test_data = X_test\n",
    "\n",
    "num_books = df.book.nunique()\n",
    "num_users = df.user.nunique()\n",
    "\n",
    "print(\"USERS: {} BOOKS: {}\".format(num_users, num_books))\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training set with three columns: user, book and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize in [0, 1]\n",
    "\n",
    "u = df['user'].values.astype(float)\n",
    "\n",
    "user_min = u.min()\n",
    "user_range = u.max() - u.min()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(u.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['user'] = df_normalized\n",
    "\n",
    "\n",
    "b = df['book'].values.astype(float)\n",
    "\n",
    "book_min = b.min()\n",
    "book_range = b.max() - b.min()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(b.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['book'] = df_normalized\n",
    "\n",
    "r = df['rating'].values.astype(float)\n",
    "\n",
    "rating_min = r.min()\n",
    "rating_range = r.max() - r.min()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(r.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['rating'] = df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert DataFrame in user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = df.pivot(index='user', columns='book', values='rating')\n",
    "matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users and items ordered as they are in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (148, 48)\n"
     ]
    }
   ],
   "source": [
    "users = matrix.index.tolist()\n",
    "books = matrix.columns.tolist()\n",
    "\n",
    "matrix = matrix.values\n",
    "\n",
    "print(\"Matrix shape: {}\".format(matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = num_books   # num of items\n",
    "num_hidden_1 = 10       # 1st layer num features\n",
    "num_hidden_2 = 5        # 2nd layer num features (the latent dim)\n",
    "\n",
    "X = tf.placeholder(tf.float64, [None, num_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    # Encoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decoder_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets are the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer, minimize the squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "predictions = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_x = tf.placeholder(tf.int32, )\n",
    "eval_y = tf.placeholder(tf.int32, )\n",
    "pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.37299580574035646\n",
      "Epoch: 2 Loss: 0.3658219575881958\n",
      "Epoch: 3 Loss: 0.3567416727542877\n",
      "Epoch: 4 Loss: 0.3453339755535126\n",
      "Epoch: 5 Loss: 0.3311205267906189\n",
      "Epoch: 6 Loss: 0.3135708510875702\n",
      "Epoch: 7 Loss: 0.2921395242214203\n",
      "Epoch: 8 Loss: 0.26648532748222353\n",
      "Epoch: 9 Loss: 0.23712715804576873\n",
      "Epoch: 10 Loss: 0.2061559945344925\n",
      "Predictions...\n",
      "      user      book    rating\n",
      "0      0.0  0.000000  0.086293\n",
      "1      0.0  0.167143  0.082039\n",
      "2      0.0  0.176429  0.974037\n",
      "3      0.0  0.177857  0.854412\n",
      "4      0.0  0.180000  0.566726\n",
      "5      0.0  0.181429  0.407169\n",
      "6      0.0  0.182857  0.217627\n",
      "7      0.0  0.211429  0.374536\n",
      "8      0.0  0.377857  0.207259\n",
      "9      0.0  0.378571  0.978924\n",
      "10     0.0  0.382857  0.848075\n",
      "11     0.0  0.383571  0.936511\n",
      "12     0.0  0.384286  0.234873\n",
      "13     0.0  0.388571  0.242593\n",
      "14     0.0  0.389286  0.260045\n",
      "15     0.0  0.390714  0.410415\n",
      "16     0.0  0.391429  0.983181\n",
      "17     0.0  0.392143  0.102749\n",
      "18     0.0  0.393571  0.255346\n",
      "19     0.0  0.465000  0.161937\n",
      "20     0.0  0.465714  0.054513\n",
      "21     0.0  0.466429  0.318109\n",
      "22     0.0  0.467143  0.116430\n",
      "23     0.0  0.467857  0.183338\n",
      "24     0.0  0.472143  0.099173\n",
      "25     0.0  0.472857  0.952072\n",
      "26     0.0  0.473571  0.187498\n",
      "27     0.0  0.474286  0.250057\n",
      "28     0.0  0.475000  0.148159\n",
      "29     0.0  0.476429  0.191827\n",
      "...    ...       ...       ...\n",
      "7074   1.0  0.393571  0.262749\n",
      "7075   1.0  0.465000  0.147668\n",
      "7076   1.0  0.465714  0.050484\n",
      "7077   1.0  0.466429  0.325143\n",
      "7078   1.0  0.467143  0.125942\n",
      "7079   1.0  0.467857  0.193747\n",
      "7080   1.0  0.472143  0.096123\n",
      "7081   1.0  0.472857  0.952288\n",
      "7082   1.0  0.473571  0.197601\n",
      "7083   1.0  0.474286  0.233609\n",
      "7084   1.0  0.475000  0.153604\n",
      "7085   1.0  0.476429  0.194637\n",
      "7086   1.0  0.477857  0.086617\n",
      "7087   1.0  0.478571  0.376411\n",
      "7088   1.0  0.479286  0.298765\n",
      "7089   1.0  0.493571  0.448029\n",
      "7090   1.0  0.503571  0.187468\n",
      "7091   1.0  0.507143  0.210418\n",
      "7092   1.0  0.551429  0.528535\n",
      "7093   1.0  0.552143  0.141292\n",
      "7094   1.0  0.556429  0.004100\n",
      "7095   1.0  0.557143  0.283681\n",
      "7096   1.0  0.774286  0.199333\n",
      "7097   1.0  0.844286  0.090515\n",
      "7098   1.0  0.891429  0.029502\n",
      "7099   1.0  0.898571  0.221565\n",
      "7100   1.0  0.899286  0.006616\n",
      "7101   1.0  0.900714  0.262517\n",
      "7102   1.0  0.924286  0.174402\n",
      "7103   1.0  1.000000  0.155068\n",
      "\n",
      "[7104 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(local_init)\n",
    "\n",
    "    num_batches = int(matrix.shape[0] / batch_size)\n",
    "    matrix = np.array_split(matrix, num_batches)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_cost = 0\n",
    "\n",
    "        for batch in matrix:\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "        print(\"Epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "\n",
    "        # if i % display_step == 0 or i == 1:\n",
    "        #     print('Step %i: Minibatch Loss: %f' % (i, l))\n",
    "\n",
    "    print(\"Predictions...\")\n",
    "\n",
    "    matrix = np.concatenate(matrix, axis=0)\n",
    "\n",
    "    preds = session.run(decoder_op, feed_dict={X: matrix})\n",
    "\n",
    "    # print(matrix)\n",
    "    # print(preds)\n",
    "    \n",
    "    predictions = predictions.append(pd.DataFrame(preds))\n",
    "\n",
    "    predictions = predictions.stack().reset_index(name='rating')\n",
    "    predictions.columns = ['user', 'book', 'rating']\n",
    "    predictions['user'] = predictions['user'].map(lambda value: users[value])\n",
    "    predictions['book'] = predictions['book'].map(lambda value: books[value])\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "    keys = ['user', 'book']\n",
    "    i1 = predictions.set_index(keys).index\n",
    "    i2 = df.set_index(keys).index\n",
    "\n",
    "    recs = predictions[~i1.isin(i2)]\n",
    "    recs = recs.sort_values(['user', 'rating'], ascending=[True, False])\n",
    "    recs = recs.groupby('user').head(k)\n",
    "    recs.to_csv('prediction.csv', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['user'] = df['user'] * user_range + user_min\n",
    "predictions['book'] = df['book'] * book_range + book_min\n",
    "\n",
    "pred = predictions.sort_values(['user', 'rating'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>book</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>0.973234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>0.864996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>0.373116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>0.260792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2380.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.084835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user   book    rating\n",
       "146  2380.0  662.0  0.973234\n",
       "195  2380.0  677.0  0.864996\n",
       "127  2380.0  382.0  0.373116\n",
       "110  2380.0  375.0  0.260792\n",
       "144  2380.0  670.0  0.084835"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.loc[pred['user'] == 2380].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146    662.0\n",
       "195    677.0\n",
       "127    382.0\n",
       "110    375.0\n",
       "144    670.0\n",
       "Name: book, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.loc[pred['user'] == 2380]['book'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_2380_top = pred.loc[pred['user'] == 2380].head(10)\n",
    "\n",
    "expected_2380_book_ids = [382,670,662,375,677];\n",
    "for x in expected_2380_book_ids:\n",
    "    if x not in user_2380_top['book'].values.round(): \n",
    "        print(f'Couldn\\'t find {x} for user 2380')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>book</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>0.540582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>0.276562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>0.210676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>0.187325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>0.169834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>0.143830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>0.082351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user    book    rating\n",
       "228   1.0  1387.0  0.540582\n",
       "231   1.0  1374.0  0.276562\n",
       "227   1.0  1420.0  0.210676\n",
       "226   1.0  1526.0  0.187325\n",
       "232   1.0  1308.0  0.169834\n",
       "229   1.0  1384.0  0.143830\n",
       "233   1.0  1210.0  0.082351\n",
       "230   1.0  1385.0  0.004110"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.loc[pred['user'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228    1387.0\n",
       "231    1374.0\n",
       "227    1420.0\n",
       "226    1526.0\n",
       "232    1308.0\n",
       "229    1384.0\n",
       "233    1210.0\n",
       "230    1385.0\n",
       "Name: book, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.loc[pred['user'] == 1]['book'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_2380_top = pred.loc[pred['user'] == 1].head(10)\n",
    "\n",
    "expected_2380_book_ids = [1387,1374,1420,1526,1308,1384,1210,1385];\n",
    "for x in expected_2380_book_ids:\n",
    "    if x not in user_2380_top['book'].values.round(): \n",
    "        print(f'Couldn\\'t find {x} for user 2380')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
